Some actor names in the data aren't captured because a shortened form of the name was used. For example, we may be looking for "Freddie Prinze Jr." but the review refers to him at one point as just "Prinze".  ---> fixed by splitting names ---> could be further fixed by name tagging



We caught some Turk results that were clearly fake, but there may be many that are false results we didn't catch.


Training data: 1185 (actor, review, sentiment) data points
	446 positive (37.64%)
	518 neutral (43.71%)
	211 negative (17.81%)
	10 not rated (0.84%)

Test data: 296 (actor, review, sentiment) data points
	116 positive (39.20%)
	124 neutral (41.89%)
	53 negative (17.91%)
	3 not rated (1.01%)





Runtime of train_cnn.py (for sentiment analysis): 149m 24.021s
Runtime of train_rnn.py (1000 iterations): 16m 55.333s






word embedding: 100



Some incorrectly formatted from Turk (i.e. didn't include sentiment)